---
layout: single
title: "Natural Language Processing??"
categories: NLP
tag: [Deep-Learning, NLP]
use_math: true
---

자연어 처리는 무엇인가??

# 정의

<img src="{{site.url}}/images/240822/0001.png" width="1200" height="500">

자연어는 사람들이 일상생활에서 자연스럽게 사용하는 언어다. 즉, 우리 인간이 사용하는 언어를 자연어라고 한다.

자연어 처리는 컴퓨터가 자연언어의 의미를 분석하고, 이해하여 언어를 생성할 수 있게 만들어주는 기술이다.

# 자연어 처리는 어렵다.

<img src="{{site.url}}/images/240822/0002.png" width="1200" height="500">

자연어 처리는 쉽지 않은 작업이다. 왜냐하면 인간의 언어는 여러 가지 특성들을 갖기 때문이다.

대표적인 케이스들에 대해 살펴보면 다음과 같다.

- 다른 단어지만 유사하거나 동일한 의미를 갖는 경우.(개, 강아지)
- 다른 표현이지만 유사하거나 동일한 의미를 갖는 경우.(금연구역, 비흡연구역)
- 문법적으로 다르지만 같은 의미를 갖는 경우.(수동태 문장과 능동태 문장)
- 동일한 단어지만 문맥에 따라 다른 의미를 갖는 경우.(나는 배를 먹었다. 배를 타고 왔다.)

<img src="{{site.url}}/images/240822/0003.png" width="1200" height="500">

- 중의적인 의미의 문장은 보통 주어진 문장만으로는 정보가 부족해 정확한 의미를 파악하기 어렵다.
- 고유명사처리(문맥에 따라 의미가 달라진다.)
- 신조어(어떤 의미인지 정보가 부족)와 같은 문제들도 추가적으로 존재한다.
- 뿐만 아니라 속담, 사자성어, 숙어처럼 문장을 구성하는 단어들이 보유한 의미와 문장 자체가 의미하는 것이 다른 경우도 존재한다.

# 한국어는 영어보다 더 어렵다.

<img src="{{site.url}}/images/240822/0004.png" width="1200" height="300">

- 한국어는 교착어로 어근과 접사에 의해 단어의 의미와 기능이 정해지는데 어떤 조사가 붙는가에 따라 문장의 의미가 달라지게 되고 다른 언어에 비해 조합의 수가 더 많다.
- 단어의 순서가 문장의 의미를 결정하는 결정적인 요소는 아니기 때문에 단어 순서가 달라지더라도 문법적인 문제가 없거나 맥락을 이해하는데 문제가 없는 경우도 있다.
- 영어와 다르게 띄어쓰기의 기준이 획일화 되어 있지 않은데, 이에 의해 자연어 전처리인 토큰화 과정이 어렵다.
- "밥 먹었어", "밥 먹었어?"와 같이 평서문과 의문문이 문장부호 하나 외에는 다른 점이 없다. 즉, 문장부호가 나와있지 않았다면 의미가 명확하지 못한 경우도 존재한다.

# 언어의 단위들

그렇다면 언어라는 데이터들은 어떤 구성을 가지고 있는지 단위에 대해 먼저 정리해보자.

## 1.음절

<img src="{{site.url}}/images/240822/0005.png" width="1200" height="500">

- 음절은 ```언어를 말하고 들을 때, 하나의 덩어리로 여겨지는 가장 작은 말소리의 단위```이다.

- 사과 -> 사, 과 총 2음절
- cat(캣) -> 1음절, computer(컴퓨터) -> 3음절

## 2.형태소

<img src="{{site.url}}/images/240822/0006.png" width="1200" height="500">

- 언어에서 ```의미를 가지는 가장 작은 단위```다. 
- 일반적으로 자연언어 처리에서는 분석의 기본이 되는 토큰으로써 형태소를 이용한다.
- 의미를 갖는 가장 작은 단위이기 때문에 더 쪼개게 되면 의미가 사라지게 된다.

## 3.어절

- 한 개 이상의 형태소가 모여 구성된 단위. 자연언어는 어절단위로 띄어쓰기 되어 발화 또는 서술된다.
- ‘우리는 오늘 동해로 간다’ -> "우리는", "오늘", "동해로", "간다" 4어절

## 4.품사

<img src="{{site.url}}/images/240822/0009.png" width="1200" height="500">

- 단어를 문법상 의미, 형태, 기능에 따라 분류한 종별(명사, 대명사, 동사 등)을 의미한다.
- 쉽게 말해 문장에서 단어가 어떤 역할을 하는지에 따라 분류된 단어의 종류.
- 의미에 따른 구분 : 명사(Noun), 대명사(Pronoun), 형용사(Adjective), 부사(Adverb), 조사(Postposition), 관형사(Determiner), 감탄사(Interjection), 접속사(Conjunction)
- 이외에도 역할, 형태에 따른 구분이 존재한다.

# 언어의 구성요소

언어는 형태, 내용, 사용 3가지 구성요소가 결합되어 이루어진다.

1. 형태는 실체인 의미를 물리적으로 표현할 수 있는 방법을 말한다.
    - 음운론 : 말소리
    - 형태론 : 형태소, 단어
    - 통사론 : 문장

2. 내용 : 의미론, 단어나 문장이 갖는 실제 의미

3. 사용 : 화용론, 언어를 사용하는 상황.

## 형태론

<img src="{{site.url}}/images/240822/0010.png" width="1200" height="500">

형태소(morpheme)는 언어에서 의미를 갖는 가장 작은 단위라고 했다. 형태론은 형태소를 분석하면서 형태소 간의 상관관계를 규명하는 학문을 말한다.

talks, talker, talked, talking과 같은 단어에서 형태소는 talk와 뒤에 붙는 -s, -er, -ed, -ing와 같은 접사들도 형태소에 해당한다.

자립성을 갖는지에 따라 자립 형태소, 의존 형태소로 나뉜다.
- 자립 형태소 : 홀로 자립하여 쓸 수 있는 형태소.
- 의존 형태소 : 다른 형태소에 의존하여 쓰이는 형태소.(이/가, 맨- 과 같은 조사, 접사들도 형태소에 해당함에 유의)

또한 의미를 가지고 있는가에 따라 실질 형태소, 형식 형태소로 나뉜다.
- 실질 형태소 : 실질적인 의미를 가지고 구체적인 대상이나 동작을 표시하는 형태소.(뛰-, 칠- 은 각각 뛰는것, 칠하는것 이라는 의미를 자체적으로 보유.)
- 형식 형태소 : 시질형태소에 결합하여 말과 말 사이의 관계를 형식적으로 표시하는 형태소.

> Q.접사, 조사와 같은 의존 형태소나 형식 형태소는 불용어일까 아닐까??

마지막으로 형태소는 복수형, 과거형과 같은 여러 개의 변이형태를 가질 수 있는데 이를 이형태(allomorph)라고 한다.

## 통사론

통사론은 단어가 결합하여 구와 문장을 형성하는 규칙과 방법에 대해 연구하는 학문이다.

- "구"는 문장 내에서 하나의 단위로 기능하는 단어들의 집합을 의미한다.
- 단어보다 큰 단위지만 문장보다는 작은 단위로, 특정한 문법적 역할을 수행한다.
- 명사구, 형용사구 등등 -> "큰 집", "내 친구", "책을 읽는다"

### 구조적 모호성

구조적으로는 크게 심층구조와 표층구조로 구분할 수 있다.
- 표층구조 : 실생활에서 사용하는 단어들의 규칙적인 구조.
- 심층구조 : 화자가 문장에 대해 갖는 추상적인 정보(의미)를 담은 구조.

"나는 그녀에게 차였다", "그녀는 나를 찼다"와 같이 의미적으로는 동일하지만(심층구조는 동일하지만) 문장의 구조가 다른(표층구조가 다른) 경우도 있고, 반대로 표층구조는 하나지만 여러 가지 심층구조를 갖는 경우도 존재한다. 즉, 구조적으로 모호한 경우들이 많다.

뿐만 아니라 특정한 규칙을 기반으로 구 구조규칙이라는 것도 존재하지만 이것 역시 변형규칙이 존재하기 때문에 텍스트 데이터를 처리하는 것은 더 어렵다고 볼 수 있다.

### 반복성

언어는 반복이라는 속성을 갖고 있기 때문에 특정 구조를 반복적으로 적용할 수도 있고, 하나의 문장을 다른 문장으로 넣을 수도 있다.

- 나는 어제 꽃을 사려고 했다. -> 나는 어제 맑은 하늘 아래, 깨끗한 공기를 마시며 꽃을 사려고 했다.
- 나는 어제 친구와 밥을 먹었다. -> 엄마는 내가 어제 친구와 밥을 먹었다는 것을 모른다.

## 의미론 

<img src="{{site.url}}/images/240822/0011.png" width="1200" height="500">

말 그대로 단어, 구, 문장의 의미를 연구하는 분야로 이들이 사용될 때 전달되는 일반적인 의미를 다룬다. 즉, 특별한 상황에서 말하는 사람이 의도하는 의미는 제외한다.

- 개념적 의미 : 단어가 사용될 때 전달되는 기본적, 본질적인 의미. 
- 연상적 의미 : 사람에 따라 다른 의미를 떠올린다.

예를 들어 "겨울"이라는 단어는 개념적으로 사계졀 중 하나지만 사람에 따라 추운 날씨, 한파와 같이 부정적인 의미일 수도 있고 하얀 눈이 내리는 즐거운 날일 수도 있다.

또한 일반적인 의미를 연구하는 것이므로 "사람이 하늘을 난다"라는 문법적으로 문제가 없는 문장이 의미적으로는 어색한 문장이다.

### 의미자질

<img src="{{site.url}}/images/240822/0012.png" width="1200" height="500">

Semantic features.

- 단어의 의미를 차별화하기 위한 기본적인 구성요소로 Man, Woman, King, Queen 4개의 단어는 성별로 구분될 수도 있으나 귀족이라는 특성으로도 구분될 수 있다.
- 또한 행위를 하는 주체나 행위를 당하는, 영향을 받는 개체, 날짜, 위치 등과 같은 의미도 함축하고 있다.
- 동의어(synonymn), 반의어(antonym), 상하관계(hyponymy), 동음이철어(homophones), 동음이의어(homonyms), 다의어(polysemy), 연어(collocation)
- Word Embedding과 같이 단어를 벡터로 표현하는 때에 이러한 의미들을 파악하는 것 같다.

## 화용론

<img src="{{site.url}}/images/240822/0013.png" width="1200" height="500">

화용론은 언어적으로 보이지 않는 의미, 실제로 말하거나 쓰지 않았더라도 화자가 의미하는 바가 무엇인지 연구한다. 즉, 화자와 청자가 어디서, 어떤 때에 나눈 대화의 문맥과 관련해 문장의 의미를 체계적으로 분석하는 것이다.

- 대표적으로 물리적인 문맥(physical context)가 화용론의 주요 내용 중 하나다. 
- 맥락 : 어떤 주어진 언어 표현이 나타나는 부분과 연관 -> 단어, 구, 문장 등의 언어 표현이 사용된 환경이나 상황을 의미
- 고층 건물 숲을 걷다가 bank라는 단어를 보게 되었다면 "둑", "은행" 중에 은행에 해당한다는 것이 맥락을 통해 알 수 있다.

# 텍스트 전처리 파이프라인

<img src="{{site.url}}/images/240822/0014.jpg" width="1200" height="500">

텍스트 데이터를 머신러닝 모델로 학습시키려면 역시 데이터 전처리가 필수적이다.


<img src="{{site.url}}/images/240822/0015.png" width="1200" height="500">

- 특정 언어의 실제 사용 사례를 수집해 놓은 대규모의 텍스트 데이터베이스를 ```Corpus```라고 한다.
- HTML 태그, 특수문자, 이모티콘과 같은 의미 없는 것들부터 작업에 따라 의미 없는 단어(불용어, stopword)를 제거한다.
- Python의 ```re```라이브러리로 정규표현식을 이용하면 어느정도 불필요한 값을 제거하거나 포맷에 맞는 텍스트만 남겨둘 수도 있다.
- 단어에서 실질적인 의미만 갖는 부분만 추출하는 어간추출(Stemming)과 원본 단어를 추출하는 표제어추출(Lemmatizing)
- is, are과 같은 단어의 원형은 be. -> 그럼 이렇게 추출해서 학습한다면 추론 때는 she is, he is 처럼 나올 수 있나...?

## 첫번째 : 토큰화

<img src="{{site.url}}/images/240822/0016.png" width="1200" height="500">

앞서 본 내용들을 일부 처리한 뒤, 토큰화를 수행하며 토큰화를 수행하고 나서도 전처리를 수행한다.

여기서 말하는 토큰화(Tokenization)은 KoNLPy, NLTK와 같은 라이브러리를 사용해 텍스트 데이터를 토큰이라는 단위로 나누는 작업을 말한다.

<img src="{{site.url}}/images/240822/0017.png" width="1200" height="500">

- 문단이 주어지면 문장들을 구분해 토큰화 할 수도 있고, 문장이 주어지면 단어들을 구분해 토큰화할 수 있다.
- 또한 We are을 we're로 표기하거나 날짜 표기, 화폐단위 등의 특수문자를 어떻게 처리할지 고려해야한다.
- 즉, 토큰이 되는 기준은 어절, 단어, 형태소, 음절, 자소 등 다양하다.
- 따라서 어떤 것으 기준으로 선택하는가에 따라 토큰화 결과가 달라지며 그에 따라 모델 성능도 달라진다.

특히나 한국어 자연어 처리가 어려운 이유에서 설명했듯 한국어 토큰화는 더욱 어렵다. 조사에 따라 같은 단어가 다른 의미를 갖게 되며 띄어쓰기 기준이 명확하지 않아도 문맥이 이해되기 때문에 어렵다.

<img src="{{site.url}}/images/240822/0018.png" width="1200" height="500">

다행히도 한국어 전용 토큰화 라이브러리인 KoNLPy가 있다. 한국어를 사용하려면 꼭 해당 라이브러리를 활용하자.

> 토큰화로 만들어진 사전의 크기가 너무 크면 출력 벡터의 차원이 굉장히 커지는 문제가 있고, 너무 작으면 커버하지 못하는 단어들(OOV)가 많기 때문에 적절한 사전의 크기가 중요하다.
> Sentence Piece는 단어를 subword 단위로 분리하기 때문에 보다 작은 크기의 사전으로 많은 단어를 커버할 수 있다고 한다.

## 두번째 : 정제

corpus 내에서 토큰화 작업에 방해가 되거나 의미 없는 부분의 텍스트, 노이즈를 제거하는 작업.
- 토큰화 전에 정제하기도 하지만 이후에도 여전히 남아있는 노이즈들을 제거하기 위해 지속적으로 수행한다.
- 특수 문자 같은 의미 없는 글자뿐만 아니라 분석하고자 하는 목적에 맞지 않는 경우도 제거한다.
- 대부분 정규표현식 및 여러 라이브러리(re) 사용해 불용어, 특수문자 제거, 대소문자 통합, 중복 문구 제거, 다중 공백 통일 등을 처리한다.

불용어(Stop Words)는 분석에 큰 의미가 없는 단어로 corpus내에 빈번하게 등장하더라도 실질적인 의미를 갖지 않은 용어를 말한다.

- 전처리 할 때 어떤 것들을 불용어로 취급할 것인지 대상을 정의해야한다.
- NLTK에서는 여러 개의 불용어들을 사전에 정의해 두었다.


## 세번째 : 정규화

텍스트에서 정규화는 크게 어근추출(Stemming)과 원형복원(Lemmatization)이 있다.
- 어근추출은 어형이 변형된 단어로부터 접사 등을 제거하고 단어의 어간을 분리해내는 것 즉, 단어에서 의미가 있는 부분만 추출하는 방식.
- 원형복원은 -ed, -ing와 같은 접사가 붙었을 때 기본형 단어로 바꾸는 방식.
- 두 방식 모두 예외적인 것들을 최소화함으로써 통일성을 높혀 연산적 효율성을 증가시키고 단순화하는 역할을 한다.

### Levenshtein distance

- 하나의 문자열 s1을 다른 문자열 s2로 변환하는 최소 횟수를 두 문자열간 거리로 한다.
- 즉, 거리가 낮을수록 유사한 문자열이라 판단.
- delete, insert, substitution(치환) 세 가지 연산이 기본 단위로 연산의 횟수만큼 거리가 있는 것과 동일.
- cat -> hat은 c를 h로 치환하면 동일해지므로 거리가 1이다.

### 정규표현식

- 복잡한 문자열의 검색이나 치환 시 사용.
- 원하는 규칙에 해당하는 문자만 남기거나 제거하는 것이 가능하고 규칙에 맞는 문자열을 반환하게 할 수 있다.
